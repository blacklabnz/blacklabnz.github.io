<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/">
  <channel>
    <title>Index on blacklabnz | Data | DevOps</title>
    <link>https://blacklabnz.github.io/</link>
    <description>Recent content in Index on blacklabnz | Data | DevOps</description>
    <image>
      <url>https://blacklabnz.github.io/%3Clink%20or%20path%20of%20image%20for%20opengraph,%20twitter-cards%3E</url>
      <link>https://blacklabnz.github.io/%3Clink%20or%20path%20of%20image%20for%20opengraph,%20twitter-cards%3E</link>
    </image>
    <generator>Hugo -- gohugo.io</generator>
    <lastBuildDate>Sun, 20 Mar 2022 00:00:00 +0000</lastBuildDate><atom:link href="https://blacklabnz.github.io/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>Purview Lineage: Part A Databricks Manual Lineage</title>
      <link>https://blacklabnz.github.io/posts/purview-lineage-manual/</link>
      <pubDate>Sun, 30 Oct 2022 00:39:13 +1300</pubDate>
      
      <guid>https://blacklabnz.github.io/posts/purview-lineage-manual/</guid>
      <description>Purview has been published by Microsoft as a unified data governance solution to help manage and govern your multi-cloud, SaaS and on prem data. You can create a holistic and up-to-date view of your data landscape with automated data discovery, data classification and end to end lineage. This provides data users with valuable, trustworthy data management. While the auto scanned lineage is useful most of the times, there are always cases where you need to manually generate your lineage graph.</description>
    </item>
    
    <item>
      <title>Databricks row and column level security</title>
      <link>https://blacklabnz.github.io/posts/databricks-row-security/</link>
      <pubDate>Sat, 30 Apr 2022 23:39:13 +1300</pubDate>
      
      <guid>https://blacklabnz.github.io/posts/databricks-row-security/</guid>
      <description>Recently I had a chat with one of client regarding on access control of their reports and dashboards. Interestingly it was found out that client is currently doing this by creating similar reports and granting access to people in different security groups. Obviously this is not the best idea because of redundant reports, the ideal solution is to implement row and column level security on the table so that people in different access groups will have visibility to subsets of the rows in the table or view.</description>
    </item>
    
    <item>
      <title>Azure networking: Hub and spoke topology with terraform</title>
      <link>https://blacklabnz.github.io/posts/hub-spoke/</link>
      <pubDate>Mon, 11 Apr 2022 00:00:00 +0000</pubDate>
      
      <guid>https://blacklabnz.github.io/posts/hub-spoke/</guid>
      <description>The hub and spoke topology has been widely adopted for enterprise production deployment. In this lab, let put on our network/infrastructure engineer hat and get our hand dirty on Azure Hub and spoke topology with one of the popular IaC &amp;ndash; Terraform. Lets have a look at the high level architecture first.
Overall architecture of the lab The essence of the topology is, by the name of it, having all traffic routed to hub before it gets forwarded to spoke.</description>
    </item>
    
    <item>
      <title>Secure Databricks cluster with vNet injection and access resources via Azure private endpoint</title>
      <link>https://blacklabnz.github.io/posts/databricks-secure/</link>
      <pubDate>Mon, 28 Mar 2022 23:39:13 +1300</pubDate>
      
      <guid>https://blacklabnz.github.io/posts/databricks-secure/</guid>
      <description>What an interesting topic I had recently regarding on security hardening Databricks using Secure cluster connectivity + vNet injection.
This configuration will allow the cluster to access Azure Data Lake Storage (I know right ?! what a popular combination!) and keyvault with private endpoint.
In this post, in a lab environment, we will find out how we can put Databricks cluster inside existing Azure virtual network and access private endpoint deployed inside it.</description>
    </item>
    
    <item>
      <title>About</title>
      <link>https://blacklabnz.github.io/about/</link>
      <pubDate>Sun, 20 Mar 2022 00:00:00 +0000</pubDate>
      
      <guid>https://blacklabnz.github.io/about/</guid>
      <description>Hi there, great to meet you here. My name is Neilï¼Œcurrently working as a Data Engineer operating in the cloud.
Previously I was working in DevOps capacity, focusing on building useful CICD pipelines, automations, APIs and else.
Through out my career, I&amp;rsquo;d like to share some tips and tricks which I hope you find helpful !</description>
    </item>
    
    <item>
      <title>Consume Websocket stream and send to Prometheus in Python</title>
      <link>https://blacklabnz.github.io/posts/websocket-prometheus/</link>
      <pubDate>Fri, 18 Mar 2022 23:39:13 +1300</pubDate>
      
      <guid>https://blacklabnz.github.io/posts/websocket-prometheus/</guid>
      <description>Recently I was tasked with consuming data from websocket, analyze it and then send data to Prometheus. The theory is pretty straight forward: getting data from websocket API in a stream and analyze and take the data points and send it to prometheus for visualization. In this blog you will have all the steps and code needed to reproduce this flow. With this in mind, I decided using python to achieve all these.</description>
    </item>
    
    
    
  </channel>
</rss>
